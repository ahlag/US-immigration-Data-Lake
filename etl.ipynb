{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, re\n",
    "import configparser\n",
    "from datetime import timedelta, datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, when, lower, isnull, year, month, dayofmonth, hour, weekofyear, dayofweek, date_format, to_date\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, DoubleType, LongType\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The AWS key id and password are configured in a configuration file \"dl.cfg\"\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "# Reads and saves the AWS access key information and saves them in a environment variable\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['KEYS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['KEYS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Read US Cities Demo dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographics=spark.read.csv(\"us-cities-demographics.csv\", sep=';', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Verifying Total Number of Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Print Schema to verify that all the columns are in \"string\" format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cast_type(df, cols):\n",
    "    \"\"\"\n",
    "    Convert the types of the columns according to the configuration supplied in the cols dictionary in the format {\"column_name\": type}\n",
    "    \n",
    "    Args:\n",
    "        df (:obj:`SparkDataFrame`): Spark dataframe to be processed. \n",
    "            Represents the entry point to programming Spark with the Dataset and DataFrame API.\n",
    "        cols (:obj:`dict`): Dictionary in the format of {\"column_name\": type} indicating what columns and types they should be converted to\n",
    "    \"\"\"\n",
    "    for k,v in cols.items():\n",
    "        if k in df.columns:\n",
    "            df = df.withColumn(k, df[k].cast(v))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Convert numeric columns to the proper types: Integer and Double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "int_cols = ['Count', 'Male Population', 'Female Population', 'Total Population', 'Number of Veterans', 'Foreign-born']\n",
    "float_cols = ['Median Age', 'Average Household Size']\n",
    "demographics = cast_type(demographics, dict(zip(int_cols, len(int_cols)*[IntegerType()])))\n",
    "demographics = cast_type(demographics, dict(zip(float_cols, len(float_cols)*[DoubleType()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Get aggregation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "first_agg = {\"Median Age\": \"first\", \"Male Population\": \"first\", \"Female Population\": \"first\", \n",
    "            \"Total Population\": \"first\", \"Number of Veterans\": \"first\", \"Foreign-born\": \"first\", \"Average Household Size\": \"first\"}\n",
    "\n",
    "# First aggregation - City\n",
    "agg_df = demographics.groupby([\"City\", \"State\", \"State Code\"]).agg(first_agg)\n",
    "\n",
    "# Pivot Table to transform values of the column Race to different columns\n",
    "piv_df = demographics.groupBy([\"City\", \"State\", \"State Code\"]).pivot(\"Race\").sum(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(City='Rockville', State='Maryland', State Code='MD', first(Total Population)=66998, first(Female Population)=35793, first(Median Age)=38.1, first(Number of Veterans)=1990, first(Foreign-born)=25047, first(Male Population)=31205, first(Average Household Size)=2.6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(City='Delray Beach', State='Florida', State Code='FL', American Indian and Alaska Native=None, Asian=1696, Black or African-American=21138, Hispanic or Latino=6397, White=40980)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Rename column names removing the spaces to avoid problems when saving to disk (we got errors when trying to save column names with spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographics = agg_df.join(other=piv_df, on=[\"City\", \"State\", \"State Code\"], how=\"inner\")\\\n",
    "                    .withColumnRenamed('State Code', 'StateCode')\\\n",
    "                    .withColumnRenamed('first(Total Population)', 'TotalPopulation')\\\n",
    "                    .withColumnRenamed('first(Female Population)', 'FemalePopulation')\\\n",
    "                    .withColumnRenamed('first(Male Population)', 'MalePopulation')\\\n",
    "                    .withColumnRenamed('first(Median Age)', 'MedianAge')\\\n",
    "                    .withColumnRenamed('first(Number of Veterans)', 'NumberVeterans')\\\n",
    "                    .withColumnRenamed('first(Foreign-born)', 'ForeignBorn')\\\n",
    "                    .withColumnRenamed('first(Average Household Size)', 'AverageHouseholdSize')\\\n",
    "                    .withColumnRenamed('Hispanic or Latino', 'HispanicOrLatino')\\\n",
    "                    .withColumnRenamed('Black or African-American', 'BlackOrAfricanAmerican')\\\n",
    "                    .withColumnRenamed('American Indian and Alaska Native', 'AmericanIndianAndAlaskaNative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- StateCode: string (nullable = true)\n",
      " |-- TotalPopulation: integer (nullable = true)\n",
      " |-- FemalePopulation: integer (nullable = true)\n",
      " |-- MedianAge: double (nullable = true)\n",
      " |-- NumberVeterans: integer (nullable = true)\n",
      " |-- ForeignBorn: integer (nullable = true)\n",
      " |-- MalePopulation: integer (nullable = true)\n",
      " |-- AverageHouseholdSize: double (nullable = true)\n",
      " |-- AmericanIndianAndAlaskaNative: long (nullable = true)\n",
      " |-- Asian: long (nullable = true)\n",
      " |-- BlackOrAfricanAmerican: long (nullable = true)\n",
      " |-- HispanicOrLatino: long (nullable = true)\n",
      " |-- White: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "                    'TotalPopulation', \n",
    "                    'FemalePopulation', \n",
    "                    'MedianAge', \n",
    "                    'NumberVeterans', \n",
    "                    'ForeignBorn', \n",
    "                    'MalePopulation', \n",
    "                    'AverageHouseholdSize', \n",
    "                    'AmericanIndianAndAlaskaNative', \n",
    "                    'Asian', \n",
    "                    'BlackOrAfricanAmerican', \n",
    "                    'HispanicOrLatino', \n",
    "                    'White'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Fill the null values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographics = demographics.fillna(0, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- StateCode: string (nullable = true)\n",
      " |-- TotalPopulation: integer (nullable = true)\n",
      " |-- FemalePopulation: integer (nullable = true)\n",
      " |-- MedianAge: double (nullable = false)\n",
      " |-- NumberVeterans: integer (nullable = true)\n",
      " |-- ForeignBorn: integer (nullable = true)\n",
      " |-- MalePopulation: integer (nullable = true)\n",
      " |-- AverageHouseholdSize: double (nullable = false)\n",
      " |-- AmericanIndianAndAlaskaNative: long (nullable = true)\n",
      " |-- Asian: long (nullable = true)\n",
      " |-- BlackOrAfricanAmerican: long (nullable = true)\n",
      " |-- HispanicOrLatino: long (nullable = true)\n",
      " |-- White: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Now write (and overwrite) transformed `demographics` dataset onto parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographics.write.mode('overwrite').parquet(\"us_cities_demographics.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read i94 immigration dataset\n",
    "\n",
    "immigration=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Fill the null values with 0\n",
    "demographics = demographics.fillna(0, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
